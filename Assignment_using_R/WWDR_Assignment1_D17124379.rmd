---
title: "Working with Data - Assignment 1"
author: "D17124379"
output: html_document
---

```{r setup,include=FALSE,warning=FALSE,error=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=10, fig.height=7) 
library(dplyr)
library(ggplot2)
library(readr)
library(httr)
library(knitr)
library(stringr)
library(lubridate)
library(scales)

```

###___Dublin Employment Trends Per Sector: 2006 - 2016___

The graph displays employment trends in Dublin from the year 2006 to 2016 in seven major sectors, namely, Construction, Finance, IT, Retail, Scientific Research, Tourism and Transport. 
By looking at the graph it can be seen that IT and Tourism sectors have seen a huge increase in employment in the recent years. The growth was slow for these sectors in the beginning, but the employment rate has improved from twenty to forty-three.
The next two sectors which are catching up with these two sectors are Scientific and Transport. Scientific research has seen a sharp downfall in the employment after twentieth quarter, however it has been improving from the end of the quarter. Employment rate in Transport sector was doing good until twentieth quarter when it started facing the lows. However, after two quarters of downs in employment, it is now catching up and employment rates are improving immensely.
As can be seen in the graph, there were no or very less opportunities in the field of Finance. However, this scenario changed by the end of first quarter and even though there have been a high number of fluctuation in employment rates in the past twenty three quarters, the sector has been doing quite well now. 
Construction sector shows one of the best employment trends in the initial quarters, but there are not too many jobs in this sector from quite some time now.  It has seen a downfall in the trends from almost twenty three quarters and is not making a great improvement in this respect too. 
Same as Construction sector, Retail sector too had a good start as compared to other sectors in terms of employment opportunity. But it has been facing a serious decline from almost thirty quarters now.
Overall, serious measures should be taken in Retail and Construction sectors to improve the employment rate. Also, steps can be taken to lessen the fluctuations and improve consistency in the trends for Finance sector.


```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#Plots.R
#1.1

dub_emp_trend <- read_delim('dublin employment trends.txt', delim = ':')
qplot(Time, Employment, data = dub_emp_trend, xlab = "Quarterly Figures", ylab = "Trend", geom = 'line', 
      main = "Dublin Employment Trends Per Sector: 2006 - 2016") + facet_grid(. ~ Sector)

```

###__Dublin Property Trends: 2007 - 2016__

The following graph shows property trends like house and apartment rental, prices and house built in Dublin from 2007 to 2016. 
Usually the variables shown in the graph (Apartment Rental, House Prices, House Rental, Houses Built) are interconnected. For example, if the houses available or built are less than the demand, then there are high chances that the rental prices will go up, or vice versa. Another way to think about this is that if the price to build houses is high then house built will be less. Now let's consider the property trend graph to find out if there is any relation between the variables presented.
As can be seen from the graph that trend lines for House Prices and House Built, and trend lines for Apt(Apartment) Rental and House Rental are trending closely. 
From tenth quarter we can say that more houses were being build and house prices were slightly more. House and apartment rents were less during the first quarter. In twentieth and thirtieth quarter, there was a drop in building houses and the house prices also fell during these quarters. House and apartment rents also declined during this time. Near the end of thirtieth quarter, there was a slight increase in the house built and prices, but from fortieth quarter onwards they are not fluctuating much. However, there is a sharp increase in the House and Apartment Rentals towards the end of fortieth quarter.
Overall, based on the trends seen above, it can be said that house and apartment rents has a direct relation with Houses Built. Also, it can be concluded that House Prices have an inverse relationship with House Built.


```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#Plots.R
#1.2
dub_prop_trend <- read_tsv('dublin property trends.txt')
View(dub_prop_trend)
qplot(Time, Trend, data = dub_prop_trend, colour = Category, geom = 'line', 
      main = "Dublin Property Trends: 2007 - 2016")

```

###__Dublin Bikes__
After its launch in 2009, Dublin bikes has been serving as one of the most popular mode of transportation in Dublin. It is a public bicycle rental scheme which serves as an easy way of commute to college, place of work, restaurants, home etcetera. Dublin bikes were launched with 450 bikes and 40 stations. Today it comprises of 100 stations with over three thousand bikes available for the  riders(Refer to the data frame 'Summary_dub_bikes').

```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#BikeInfo.R
#2.1

#Extracting real time bikes information from the following url
url_api = 'https://api.jcdecaux.com/vls/v1/stations?'
response = GET(url_api, query = 
                 list(apiKey = '537eb2f907c103123b3b0bc9c53840771c9cb529', 
                      contract = 'dublin'))
bike_info = content(response)

bikeData = data.frame(NULL)
len_bike = length(bike_info)

#loop to create data frame
for (i in 1: len_bike){
  df = data.frame(bike_info[i])
  bikeData = rbind(bikeData, df)
}
View(bikeData)

#Creating data frame for only the columns of interest
bike_overview <- bikeData[ , c("name", "address", "banking", "bike_stands", 
                               "available_bike_stands", "available_bikes")]
View(bike_overview)

```


2.1 When having a brief conversation with the manager of Dublin bikes, the following information such as total number of bike stations, stations with or without baking facility, total bike stands across all the stations and how many are available in them and available bikes available will be some of the interesting points he would be interested to know.Also, he would want to know the busiest stations among all the stations. According to Dublin app if there is less or no space available to park bikes, then it is considered busy and based on this information busy stations has been tried to find out.

```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#total number of bike stations
tot.bke.statn <- nrow(bike_overview)

#how many stations has banking facility available and how many do not
statn.with.bankfacility <- sum(bike_overview$banking == "TRUE")
statn.without.bankfacility <- sum(bike_overview$banking == "FALSE")

#total number of bike stands across all the bike stations
tot.bke.stnds <- sum(bike_overview$bike_stands)

#available number of bike stands across all stations
tot.avl.bke.stnds <- sum(bike_overview$available_bike_stands)

#bikes available 
tot.bkes.avl <- sum(bike_overview$available_bikes)

#Average available stands and bikes
avg.available.stands <- round(mean(bike_overview$available_bike_stands))
avg.available.bikes <- round(mean(bike_overview$available_bikes))

#To put all the information collected above in one data frame
Information <- c("Total bike stations in Dublin", "Number of stations with banking facility", 
                 "Number of stations without banking facility", "Total bike stands across all bike stations",
                 "Available bike stands", "Available bikes", "Average available stands", "Average available bikes")

Count <- c(nrow(bike_overview), statn.with.bankfacility, statn.without.bankfacility, 
           tot.bke.stnds, tot.avl.bke.stnds, tot.bkes.avl, avg.available.stands, avg.available.bikes)

Summary_dub_bikes <- data.frame(Information, Count)
kable(Summary_dub_bikes)

#to find a list of most busy bike stations in Dublin
busy.bke.statn <- bike_overview$available_bike_stands < 5
busy.bke.statn.df <- bike_overview[busy.bke.statn, ]
kable(busy.bke.statn.df)

```


2.2 Suppose I want to take a bike to go to a friend's place and I do not want to rely on the bus for the entire journey to save time. So I want to check the stations where there are atleast 15 bikes available, so that I am sure that by the time I will reach that station I will still have bikes available for me. Also, due to the system of dublin bikes I will need to park somewhere as well, so I will also like to see the stations where there are sufficient number of bike stands available.So a data frame is obtained firs considering this in mind. Then a graph is plotted filtering on the basis of banking available at the station or not, as this is also an important aspect for me to know as I am not sure of the available balance in my leap card.

```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

bike.info <- filter(bike_overview, available_bike_stands > 12 & available_bikes > 15)
qplot(name, available_bikes, data = bike.info, xlab = "Name of Stations", ylab = "Number of bikes available", colour = banking) + theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

###__Dublin Bus__

Dublin bus is huge transportation network in Dublin, used by almost every class and category of people. There can be many interesting points to know about this network. But before performing the exploratory data analysis, dataset was downloaded from the dublin bus website, viewed to find the tables of interest and then joined to use the information in a meaningful manner and obtain answers to relevant questions. 

```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#download the dataset from the internet, unzip it and view the files
download.file('https://data.dublinked.ie/dataset/a97edfe6-1ee2-494c-9998-c7ab29214d59/resource/e95bd0b4-1ac3-471d-93ea-2d129c8e8dfe/download/googletransitdublinbusp20130315-1546.zip', 
              destfile = 'DublinBusGTFS.zip')
unzip('DublinBusGTFS.zip', exdir = './DublinBusGTFSData')
files.list <- list.files('DublinBusGTFSData')

#importing the files to R
agency <- read_csv('./DublinBusGTFSData/agency.txt')
calendar <- read_csv('./DublinBusGTFSData/calendar.txt')
calendar.dates <- read_csv('./DublinBusGTFSData/calendar_dates.txt')
routes <- read_csv('./DublinBusGTFSData/routes.txt')
shapes <- read_csv('./DublinBusGTFSData/shapes.txt')
stop.times <- read_csv('./DublinBusGTFSData/stop_times.txt')
stops <- read_csv('./DublinBusGTFSData/stops.txt')
transfers <- read_csv('./DublinBusGTFSData/transfers.txt')
trips <- read_csv('./DublinBusGTFSData/trips.txt')

#Shaping the data frames for the necessary files
trips <- trips %>%
  select(-c(trip_headsign, block_id)) %>%
  group_by(route_id)
stops <- group_by(stops, stop_name)
stop.times <- select(stop.times, -c(departure_time, pickup_type, drop_off_type))
shapes <- group_by(shapes, shape_id)
dist.shape.covered <- summarise(shapes, total_dist_traveled = max(shape_dist_traveled))
routes <- select(routes, -c(agency_id, route_type))
calendar <- select(calendar, -c(start_date, end_date))

#joining tables of interest
stoptimes <- inner_join(stops, stop.times, by = 'stop_id')
shapes.trips <- inner_join(dist.shape.covered, trips, by = 'shape_id')
trips.routes <- inner_join(routes, shapes.trips, by = 'route_id')
trips.stoptimes <- inner_join(stoptimes, trips.routes, by = 'trip_id')
detailed.trips.frame <- inner_join(calendar, trips.stoptimes, by = 'service_id')

```

3.1 After the above mentioned steps, exploratory analysis was performed and some important questions were tried to answer using the dublin bus data set. There are more than 4724 stops in dublin which is a huge number and shows that the bus network is good and expanded probably covering each and every area of the city. It was noticed that the area 'Blessington Road' has the most number of stops that is 79 followed by Malahide Road and Howth Road with 64 and 59 stops respectively. It can be said that these areas are possibly big and more number of people commute from or to these areas.Not only Malahide Road has the more number of stops but most number of buses are also accessible from this area.
After that the next question which was tried to answer is the minimum and maximum distance travelled on each route. The bus on 'Strand Road to Shanard Avenue' covers the maximum distance of approximately 12000 metres.Next, a graph is plotted to display the trips made per route. It can be seen that 46A covers the maximum number of trips(approx. 600) followed by route 40 with approx. 450 trips per route and route 145 with approx. 420 trips per route.The next graph plots number of trips based on services. As per 'calendar' data frame, service 1 operates on weekdays, service 2 on monday and sunday, and service 3 oprates on just saturday. From the graph 'Trips covered for each service', it is clear that service 1 covers most number of trips with approx. 7000 and service 2 covers the least number of trips with approx. 4000. The interesting thing to notice in this graph is that service 3 which operates only saturday covers second largest number of trips with more than 5500 trips. From this it can be said that more number of people commutes on saturday(weekend) may to go for shopping, work or visiting relatives but on sunday people do not commute so much, this can be confirmed as service 2 operates on monday and sunday but still serves less number of trips.. 
```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#DublinBus.R
#3.1

#EXPLORATORY DATA ANALYSIS

#how many stops are there in Dublin?
tot.stops <- length(unique(stops$stop_id))
cat("Total number of stops in Dublin", tot.stops)

#how many stops are there in each area?
stops.count <- stops %>%
  summarise(total_stops = sum(!is.na(stop_id))) %>%
  arrange(desc(total_stops))
cat("Total number of stops in each area")
kable(head(stops.count))

#how many buses can be accessed from a particular area?
bus.count.by.area <- stoptimes %>%
  summarise(no_of_buses_accessible = sum(!is.na(stop_name))) %>%
  arrange(desc(no_of_buses_accessible))
cat("Number of buses available from each area")
kable(head(bus.count.by.area))


#minimum and maximum distance covered by every route?
trips.routes.grp1 <- group_by(trips.routes, route_id, route_long_name)
route.travelled <- trips.routes.grp1 %>%
  summarise(min_dist_traveled = min(total_dist_traveled), max_dist_traveled = max(total_dist_traveled))
arrange(route.travelled, desc(max_dist_traveled))
cat("Minimum and Maximum distance travelled by bus on each route")
kable(head(route.travelled))

#trips made per route
ggplot(data = trips.routes) + geom_bar(mapping = aes(x = route_short_name)) + labs(x = "Routes(by short name)", y = "Trips made per route") + theme(axis.text.x = element_text(angle = 90, hjust = 1))

#trips made for each service
qplot(sort(service_id), data = trips.routes, xlab = "Services", ylab = "No. of Trips", 
      geom = 'bar', main = "Trips covered for each service", colour = I('cyan'))

```

3.2 The route I have selected is 39A(Hansfield Road - University College Dublin) as this is the route I take everyday to commute from my home to college. To become an expert on this route I would like to answer following questions.

```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#DublinBus.R
#3.2

route39A <- filter(trips.stoptimes, route_short_name == '39A')

#how many buses arrives/ departs from each area?
route39A.grp1 <- route39A %>%
  group_by(stop_name) %>%
  summarise(no.of.buses = sum(!is.na(trip_id)))
cat("Number of buses arriving and departing from each area")
ggplot(data = route39A.grp1) + geom_col(aes(x = reorder(stop_name, -no.of.buses), 
                                            y = no.of.buses), fill = "dodgerblue4") + labs(x = "Name of Stops", y = "Number of Buses", title = "Number of 39A buses arriving/ departing in each area") + theme(axis.text.x = element_text(angle = 90, hjust = 1))

#data frames based on directions(outbound(1)-going towards college/ inbound(0)-coming towards home)
route39A.dir1 <- route39A %>%
  filter(direction_id == 1) %>%
  arrange(arrival_time)
route39A.dir0 <- route39A %>%
  filter(direction_id == 0) %>%
  arrange(arrival_time)

#Filtering out particular stop that is 'Navan Road'(stop_sequence 32) from where I take bus to college 
stop32 <- route39A.dir1 %>%
  filter(stop_sequence == 32) %>%
  arrange(arrival_time)
#changing the format of 'arrival_time' variable
stop32$arrival_time <- format(stop32$arrival_time, "%H:%M:%S")
#How many buses go towards college
cat("Number of buses from home towards college are ",length(unique(stop32$trip_id)))


#Filtering out particular stop that is 'Aston Quay'(stop_sequence 22) from where I take bus to college 
stop22 <- route39A.dir0 %>%
  filter(stop_sequence == 22) %>%
  arrange(arrival_time)
stop22$arrival_time <- format(stop22$arrival_time, "%H:%M:%S")
#How many buses come in the direction of my home when coming back from college?
cat("Number of buses from college towards home are ", length(unique(stop22$trip_id)))


#Frequency of buses before 11am while going towards college
y <- "11:00:00"
bus.avl.32 <- strptime(stop32$arrival_time, "%H:%M:%S") < strptime(y, "%H:%M:%S")
cat("Number of buses before 11am are ", sum(bus.avl.32))
#first 39A bus at my stop
cat("First bus from home is at ", min(stop32$arrival_time))

#Frequency of buses after 6pm when coming back home in the evening
x <- "18:00:00"
bus.avl.22 <- strptime(stop22$arrival_time, "%H:%M:%S") > strptime(x, "%H:%M:%S")
cat("Number of buses after 6pm are ", sum(bus.avl.22))
#last bus when coming back from college
cat("Last bus from college is at ", max(stop22$arrival_time))

#Time taken to reach college
#Mostly, I take bus around 9.30am, so I am chosing a trip_id for this '3110.2978.0-39A-b12-1.247.I' from stop_sequence 32
# and I get down at stop_sequence 50 and stop no. 1479
time.to.reach <- (route39A.dir1$stop_sequence == 32 | route39A.dir1$stop_sequence == 50) & 
  (route39A.dir1$trip_id == '3110.2978.0-39A-b12-1.247.I')
time.to.reach.stp50 <- route39A.dir1[time.to.reach, ]
time.to.reach.stp50$arrival_time <- format(time.to.reach.stp50$arrival_time, "%H:%M:%S")
max.time <- max(time.to.reach.stp50$arrival_time) 
min.time <- min(time.to.reach.stp50$arrival_time)
total.time.taken <- strptime(max.time, "%H:%M:%S") - strptime(min.time, "%H:%M:%S")
cat("Time taken when returning home ", round(total.time.taken))

#time taken to come back home
#Mostly, I take bus around 7 pm, so I am chosing a trip_id for this '10039.2955.0-39A-b12-1.244.O' from stop_sequence 32
# and I get down at stop_sequence 50 and stop no. 1479
time.to.reach.back <- (route39A.dir0$stop_sequence == 22 | route39A.dir0$stop_sequence == 39) & 
  (route39A.dir0$trip_id == '10039.2955.0-39A-b12-1.244.O')
time.to.reach.stp39 <- route39A.dir0[time.to.reach.back, ]
time.to.reach.stp39$arrival_time <- format(time.to.reach.stp39$arrival_time, "%H:%M:%S")
max.timeb <- max(time.to.reach.stp39$arrival_time) 
min.timeb <- min(time.to.reach.stp39$arrival_time)
tot.time.taken <- strptime(max.timeb, "%H:%M:%S") - strptime(min.timeb, "%H:%M:%S")
cat("Time taken when returning home ", round(tot.time.taken))


#How many stops are there in my route
df.filtered.route <- route39A.dir1 %>%
  filter(trip_id == '3110.2978.0-39A-b12-1.247.I') %>%
  arrange(stop_sequence)
all.stops <- between(df.filtered.route$stop_sequence, 32, 50)
all.stops <- sum(all.stops)
total.stops <- all.stops - 2
cat("Number of stops in my route ", total.stops)

#Average distance travelled per trip
avg.dist <- mean(trips.stoptimes$total_dist_traveled)
cat("Average distance travelled per trip ", avg.dist)

#finding variation in time for direction 0 and 1
route39A.grp3 <- group_by(route39A, trip_id)

route39A.dir0<- route39A.dir0 %>%
  group_by(trip_id) %>%
  mutate(start_time=min(arrival_time),end_time=max(arrival_time))
route39A.dir0$start_time<-as.POSIXct(route39A.dir0$start_time,format = "%H:%M:%S")
route39A.dir0$end_time<-as.POSIXct(route39A.dir0$end_time,format = "%H:%M:%S")
route39A.dir0<- route39A.dir0 %>%
  group_by(trip_id) %>%
  mutate(time_taken=difftime(end_time,start_time,units="mins"))
route39A.dir0$time_taken<-as.numeric(route39A.dir0$time_taken)

route39A.dir1<- route39A.dir1 %>%
  group_by(trip_id) %>%
  mutate(start_time=min(arrival_time),end_time=max(arrival_time))
route39A.dir1$start_time<-as.POSIXct(route39A.dir1$start_time,format = "%H:%M:%S")
route39A.dir1$end_time<-as.POSIXct(route39A.dir1$end_time,format = "%H:%M:%S")
route39A.dir1<- route39A.dir1 %>%
  group_by(trip_id) %>%
  mutate(time_taken=difftime(end_time,start_time,units="mins"))
route39A.dir1$time_taken<-as.numeric(route39A.dir1$time_taken)

#graph to plot variation in time
cat("Red line indicates time taken when going to college and Blue line indicates time taken by bus when coming back home")
ggplot()+geom_smooth(data=route39A.dir0,aes(x=start_time,y=time_taken),na.rm=T,colour="blue")+geom_smooth(data=route39A.dir1,aes(x=start_time,y=time_taken),na.rm=T,colour="red")+labs(title="Variation of total time taken during different point of time",x="Start Time",y="Total Time Taken")


```

1. From the graph 'Number of 39A buses arriving/ departing in each area' it can be seen that most number of buses crosses from 'Navan Road' which is a good news for me, as my bus stop near home lies on this road.
2. The next thing I would like to know is the total number of buses going towards college from my place and it is found out to be 203, but the number of buses coming from the college towards my home are 195.
3. As on all the weekdays I take the bus to college before 11am, so I would like to know the frequency count of the buses before that and it is 57, which is a good news to me. The first bus from my place is as early as 5:46 am. I performed the same action when comin back from college. My classes mostly ends by 5pm and I take bus at or after 6pm. So the frequency of buses after 6pm is 58 and last bus is as late as 11:53pm. This is an important information for me in case I chose to study in the library till late. 
4. Next attempt is to answer how much time is taken to reach college in the morning and while coming back. A difference of just two minutes is found in the time taken in the morning as compared to what is taken in the evening, which is nominal. It can be said that either the route taken by 39A is not busy or it is not a peak time after 7pm.
5. The number of stops that falls in my route from home to college are 17.
6. Average distance travelled per trip is approx. 21000m .
7. The graph 'Variation of total time taken during different point of time' displays that when going towards college or coming back, time taken in the morning and after 6pm is nominal. However, bus takes more time from 10am to 6pm. Most time taken is during 5pm to 6pm.

###__Reflection__

5.1 An analysis of some of the most useful commands learnt in R has been carried out from Sept 11, 2017 to Nov
19, 2017. The commands used in the analysis are read, write, qplot and ggplot. Read and write commands are very useful and important commands to learn in R. Through read command one can load files to R and write command can be used to save the file to the system.
qplot and ggplot commands are very useful for visual representation of data. qplot command is simpler than ggplot. However, ggplot can provide more functionality to our graphs.

```{r,echo = FALSE,warning=FALSE,,error=FALSE,,message=FALSE}

#Reflection.R
#5.1

#importing history data into R and giving appropiate column names
dfHistory = read.delim("history_database", sep = ":", stringsAsFactors = F, header = F)
colnames(dfHistory) = c("Time","Command")


dfHistory$Time <- strtrim(dfHistory$Time,10)
dfHistory$Time <- as.numeric(dfHistory$Time)
dfHistory$Time <- as_datetime(dfHistory$Time)

#searching for the following commands
dfHistory$CommandName <- ifelse(grepl("write", dfHistory$Command, ignore.case = T),"Write", 
                          ifelse(grepl("read", dfHistory$Command, ignore.case = T),"Read",
                          ifelse(grepl("ggplot", dfHistory$Command, ignore.case = T),"ggplot",
                          ifelse(grepl("qplot", dfHistory$Command, ignore.case = T),"qplot",
                                 NA ))))

#comparison read vs write
history.df1 <- filter(dfHistory,!is.na(CommandName),CommandName == c("Write","Read"))
ggplot(data = history.df1, aes(x=CommandName)) + geom_bar(fill = "seagreen3") + labs(title = "Read vs Write", x = "Command Name", y = "Count")

                                      
#comparison ggplot vs qplot
history.df2 <- filter(dfHistory,!is.na(CommandName),CommandName == c("ggplot","qplot"))
ggplot(data = history.df2, aes(x = CommandName)) + geom_bar(fill = "seagreen3") + labs(title = "ggplot vs qplot",x = "Command Name", y = "Count")


dfHistory$Date <- as.Date(dfHistory$Time,"%d/%m")
dfHistory$Time <- format(dfHistory$Time,"%H:%M:%S")

dfHistory <- subset(dfHistory,Date != "1970-01-01")


Count <- rle( sort( dfHistory$Time ) )

dfHistory$Count <- Count[[1]][ match( dfHistory$Time , Count[[2]] ) ]
dfHistory$Time <- format(dfHistory$Time, format = "%H:%M:%S")
dfHistory$Time <- as.POSIXct(dfHistory$Time, format = "%H:%M:%S")

#plotting for frequency of commands used over time
cat("Frequency of commands used over time")
ggplot(data = dfHistory, aes(dfHistory$Time, y = dfHistory$Count)) + geom_smooth() + scale_x_datetime(labels = date_format("%H-%M")) + labs(x = "Time",y = "Count")

```

As evident from the graph 'Read vs Write', I have used read command more number of times than write. While working with R I need to load the data sets or files for which I need to use read command everytime. However, I have not been required to write many files to the system.
From the graph 'ggplot vs qplot', it can be said that I have used qplot more than ggplot. I was introduced with qplot before ggplot. I find qplot simple and straight forward to use. However, while working on this assignment I learnt ggplot and understood the functionality it can bring to the visualisations.
The last graph displays the frequency of commands over time. As can be seen I have worked more on R during morning till afternoon. As day proceeds towards evening my work with R reduces. I am most active with R at around 12.30pm.

5.2 Personal Reflections

I was introduced to R approx. two months back as a part of my Masters programme. However, I am impressed with how much I have learned in such little time. I would say prior knowledge of C++ helped me understand few areas of this language easily, however I stuggled with a few area as well.

1. Challenges overcome
I have come across many challenging areas while working on the assignment. There were times when I knew the analysis I have to make or the result I am expecting, but finding the right set of commands to achieve that was a challenge. The work around I found was referring to the notes provided in class, seeking help from fellow classmates, and going through R manuals, and most of it worked for me.

2. Efficient work practices
Efficient work practices can involve understanding the data and its nature properly and preparing questions prior to writing code and jumping to conclusions. Proper time management is also a key aspect to reaching the deadlines in time and without getting frustrated.Sticking to the universally accepted style of writing R code is also a good work practice.

3. Areas of frustration
As mentioned in the first point, as I am not completely familiar with all the commands and funcions that can be used to perform a number of ideas or questions, hence it becomes frustrating at times when I am not even sure what I am searching for(functions or commands). Due to this reasons I had to drop a few very interesting yet very complex ideas.

4. Time management
I must say I have so much to learn about efficient time management improve at it. However, during this assignment I tried to allot more time to R code as I realised I was taking more time to answer the questions through R code due to unfamiliarity with some of the areas of R. I gave less time to writing as compared to the time given to code, because I had clear idea of the analyses I had to perform and answers I had to answer.




